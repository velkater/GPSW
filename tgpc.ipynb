{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import logging\n",
    "import math\n",
    "logging.basicConfig(format='%(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization012_rules_checker:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Prepare rules ...\n",
    "        \"\"\"\n",
    "        self._ei = {\"0\": Ei(\"0\"), \"1\": Ei(\"1\"), \"2\": Ei(\"2\")}\n",
    "        self._generate_factor_rules()        \n",
    "        self._compile_rules()\n",
    "    \n",
    "    _bad_prefixes_and_correction = (\n",
    "            (\"(00)*02\", \"0012\", 1),\n",
    "            (\"0010\", \"122100\", 2),\n",
    "            (\"00(120R)+10\", \"1220\", 3),\n",
    "            (\"0012(0R12)*01\", \"0R21\", 4),\n",
    "            (\"001221(1R11)*12\", \"1R22\", 5),\n",
    "            (\"0012211R(111R)*10\", \"1100\", 6),\n",
    "            (\"001222\", \"210012\", 7),\n",
    "            (\"0012(0R12)*00\", \"0R20\", 8),\n",
    "            (\"00(120R)*11\", \"1221\", 9),\n",
    "            (\"(001221)*00122R\", \"211R\", 10),\n",
    "            (\"(001221)*001R\",\"120R\", 11),\n",
    "            (\"(001221)+0R\",\"002R\", 12),\n",
    "            (\"(001221)+1R2R\", \"222R\", 13),\n",
    "            (\"(001221)+002R2R\", \"210R\", 14),\n",
    "            (\"(001221)*00120R2R\", \"201R\", 15),\n",
    "            (\"00(120R)*122111\", \"1R11\", 16),\n",
    "            (\"0012(0R12)*0R2022\", \"2112\", 17),\n",
    "            (\"(00)+1212\", \"1R02\", 18),\n",
    "            (\"0012(0R12)+2020\", \"2R10\", 19),\n",
    "            (\"(00)+1210\", \"1120\", 20),\n",
    "            (\"0012(0R12)*0R2112\", \"1022\", 21),\n",
    "            (\"001221(1R11)*0020\", \"2R10\", 22),\n",
    "            (\"001221(1R11)*1R2201\", \"0021\", 23),\n",
    "            (\"(00)+1202\", \"0R12\", 24),\n",
    "            (\"(00)+001111\", \"1R11\", 25),\n",
    "            (\"(00)+001020\", \"2R10\", 26),\n",
    "            (\"00(120R)+202111\", \"120021\", 27),\n",
    "            (\"(00)+121121\", \"200211\", 28),\n",
    "            (\"00(120R)+211020\", \"220110\", 29),\n",
    "            (\"001221(1R11)*1R220020\", \"211200\", 30)\n",
    "    )\n",
    "            \n",
    "    def find_applicable_rule(self, biseq):\n",
    "        \"\"\" Function looking is there is a bad prefix of a bad factor\n",
    "        inside the preprocessed biseq. If so, it returns the bad prefix position and the\n",
    "        correction to apply. If not, it returned an emply field (for now)??.\"\"\"\n",
    "    \n",
    "        logging.info(\"Checking for an applicable rule in\" + str((biseq[0::2], biseq[1::2])))\n",
    "        \n",
    "        applicable_rule = self._find_next_prefix_rule(biseq)\n",
    "        if applicable_rule:\n",
    "            return applicable_rule\n",
    "        \n",
    "        # If there is no bad prefix, we look for a factor rule\n",
    "        applicable_rule = self._find_next_factor_rule(biseq)\n",
    "        if applicable_rule:\n",
    "            return applicable_rule  \n",
    "    \n",
    "    def _find_next_prefix_rule(self, biseq):\n",
    "        # Looking for a prefix rule\n",
    "        for prefix_rule in self._prefix_rules:\n",
    "            match = re.match(prefix_rule[0], biseq)\n",
    "            if match:\n",
    "                logging.debug(\"prefix rule: \" + str(prefix_rule))\n",
    "                index = match.end() - 2\n",
    "                return [index, prefix_rule[1]] # bad prefix to repare\n",
    "    \n",
    "    def _find_next_factor_rule(self, biseq):\n",
    "        matches = []\n",
    "        for rules_index,_rules in self._factor_rules.items():\n",
    "            for rule in _rules:\n",
    "                match = re.match(rule, biseq)\n",
    "                if match:\n",
    "                    logging.debug(\"rule\" + str(rules_index) + \": \" + \\\n",
    "                    str(self._print_factor_rule(rule)) +\n",
    "                    \" in biseq \" + str((biseq[0::2], biseq[1::2])))\n",
    "                    \n",
    "                    position = match.end() - 2 # The position to be corrected\n",
    "                    #Index of match and correction:\n",
    "                    matches.append([position, self._factor_rules_replacement(rules_index, match.group(2))])\n",
    "                    biseq = biseq[:position + 3]\n",
    "\n",
    "        logging.info(\"all non-prefix matches: \" + str(matches))\n",
    "        # Final leftmost factor rule\n",
    "        if matches:\n",
    "            final = matches[0]\n",
    "            for rule in matches[1:]:\n",
    "                if rule[0] < final[0]:\n",
    "                    final = rule\n",
    "            logging.debug(\"Final change:\" + str(final))\n",
    "            return final \n",
    "    \n",
    "    def _factor_rules_replacement(self, index, rule):\n",
    "        ei = self._ei\n",
    "        if index == 1:\n",
    "            return rule[4]+\"R\"+ rule[2] + rule[3]\n",
    "        elif index == 2:\n",
    "            return rule[4]+rule[1]+rule[2] + \"R\"\n",
    "        elif index == 3:\n",
    "            return (rule[4]+ei[rule[1]][int(rule[3])] \n",
    "                    + ei[rule[1]][int(ei[rule[3]][int(rule[2])])] + rule[1])\n",
    "        elif index == 4:\n",
    "            return rule[6]+rule[1]+rule[2]+rule[3]+rule[4] + rule[5]\n",
    "        else:\n",
    "            logging.error(\"No replacement rule found\")\n",
    "    \n",
    "    def _generate_factor_rules(self):\n",
    "        ei = self._ei\n",
    "        a_b = [i[0]+i[1] for i in itertools.product('012', repeat = 2)]\n",
    "        i = [\"0\", \"1\", \"2\"]\n",
    "        \n",
    "        # we consider here b as b_2\n",
    "        self._rules1 = (k[0][0]+ \"R\" + ei[k[1]][int(k[0][1])]+ k[1] + \n",
    "                  k[0][1] + k[1] for k in itertools.product(a_b, i))\n",
    "        self._rules2 = (k[0][0]+ k[1] + ei[k[1]][int(k[0][1])]+ \"R\" + \n",
    "                  k[0][1] +\"R\" for k in itertools.product(a_b, i))\n",
    "\n",
    "        ij = itertools.permutations(\"012\", 2)\n",
    "        # we consider here b as b_1\n",
    "        self._rules3 = (k[0][0] + k[1][0] + k[0][1] + \n",
    "                   k[1][1] + ei[k[1][1]][int(ei[k[1][0]][int(k[0][1])])] + k[1][0] \n",
    "                  for k in itertools.product(a_b, ij))\n",
    "\n",
    "        ijk = itertools.permutations(\"012\", 3)\n",
    "        self._rules4 =(k[0][0] + k[1][0] + k[0][1] + k[1][1] + \n",
    "                 ei[k[1][1]][int(ei[k[1][0]][int(k[0][1])])] + k[1][2] + \n",
    "                    ei[k[1][2]][int(ei[k[1][0]][int(k[0][1])])] + k[1][2]\n",
    "                 for k in itertools.product(a_b, ijk))\n",
    "    def _compile_rules(self):\n",
    "        self._prefix_rules = tuple((re.compile(rule[0]),rule[1],rule[2])\n",
    "                                   for rule in self._bad_prefixes_and_correction)\n",
    "\n",
    "        self._factor_rules = {}\n",
    "        self._factor_rules[1] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules1 )\n",
    "        self._factor_rules[2] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules2 )\n",
    "        self._factor_rules[3] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules3 )\n",
    "        self._factor_rules[4] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules4 )\n",
    "    \n",
    "    def print_all_factor_rules_readable(self):\n",
    "        for index in self._factor_rules:\n",
    "            self._print_factor_rules(index)\n",
    "            \n",
    "    def _print_factor_rules(self, index):\n",
    "        readable_rules = []\n",
    "        print(\"Factor rules \" + str(index))\n",
    "        for rule in self._factor_rules[index]:\n",
    "            readable_rules.append(self._print_factor_rule(rule))\n",
    "        print(tuple(readable_rules))\n",
    "                                  \n",
    "    def _print_factor_rule(self, rule):\n",
    "        rule_from_regex = rule.pattern.split(\"*\")[1][1:-1]\n",
    "        return (rule_from_regex[0::2], rule_from_regex[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer012:\n",
    "    def __init__(self):\n",
    "        self._rules_checker = Normalization012_rules_checker()\n",
    "        \n",
    "    def normalize(self, delta1, theta1):\n",
    "        \"\"\"Returns the normalized directive bi-sequence giving the same GPS word\n",
    "        as (delta1, theta1)\"\"\"\n",
    "        # Changing the letters to be in order 0,1,2\n",
    "        delta, theta, substitution = self._change_letters_order(delta1, theta1)\n",
    "        \n",
    "        # Interleaving delta and theta to get only one sequence from two\n",
    "        biseq = \"\".join(d + t for d, t in zip(delta, theta))\n",
    "\n",
    "        # Normalization of the prefix\n",
    "        biseq = self._initial_normalization(biseq)\n",
    "\n",
    "        # The main algorithm:\n",
    "        applicable_rule = self._rules_checker.find_applicable_rule(biseq)\n",
    "        while applicable_rule:\n",
    "            biseq = self._apply_rule(biseq, applicable_rule);\n",
    "            applicable_rule = self._rules_checker.find_applicable_rule(biseq)\n",
    "\n",
    "        # Post-processing\n",
    "        delta, theta = (biseq[0::2], biseq[1::2])\n",
    "        logging.info(\"bi-sequence before changing the letters back: (\" +\\\n",
    "                         delta + \", \" + theta + \")\")\n",
    "\n",
    "        delta, theta = self._change_letters_order_back(delta, theta, substitution)\n",
    "        \n",
    "        notchanged = (delta1 == delta) and (theta1 == theta)\n",
    "        return (delta, theta, notchanged)\n",
    "    \n",
    "    # Preprocessing\n",
    "    @staticmethod\n",
    "    def _substitute(dic, seq):\n",
    "        \"\"\"Substitutes letters in a word according to rules in dic, if there is\n",
    "        no rule for the letter, keeps the letter.\"\"\"\n",
    "        newseq = \"\"\n",
    "        for l in seq:\n",
    "            if l in dic:\n",
    "                newseq = newseq + dic[l]\n",
    "            else:\n",
    "                newseq = newseq + l\n",
    "        return newseq\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compose_substitutions(subs1, subs2):\n",
    "        \"\"\"Composes two substitutions of letter.\"\"\"\n",
    "        csub = {}\n",
    "        for l in [\"0\", \"1\", \"2\"]:\n",
    "            if l in subs1:\n",
    "                csub[l] = subs1[l]\n",
    "                if csub[l] in subs2:\n",
    "                    csub[l] = subs2[csub[l]]\n",
    "            elif l in subs2:\n",
    "                csub[l] = subs2[l]\n",
    "        return csub\n",
    "\n",
    "    def _change_letters_order(self, delta, theta):\n",
    "        \"\"\" Change (delta, theta) so that the word obtained is the same as the \n",
    "        original one, but the first symbol is 0, the second 1 and the third 2.\"\"\"\n",
    "        subs = {}\n",
    "        subs2 = {\"2\": \"1\", \"1\": \"2\"}\n",
    "        if delta[0] != \"0\":\n",
    "            subs = {delta[0]: \"0\", \"0\": delta[0]}\n",
    "            delta = self._substitute(subs, delta)\n",
    "            theta = self._substitute(subs, theta)\n",
    "        i = 0\n",
    "        l = len(delta)\n",
    "        while i < l and delta[i] == \"0\":\n",
    "            if theta[i] == \"2\":\n",
    "                return [delta, theta, subs]\n",
    "            if theta[i] == \"1\":\n",
    "                delta = self._substitute(subs2, delta)\n",
    "                theta = self._substitute(subs2, theta)            \n",
    "                return [delta, theta, self._compose_substitutions(subs, subs2)]\n",
    "            #otherwise whe have to continue\n",
    "            i = i + 1\n",
    "        if i < l and delta[i] == \"2\":\n",
    "            delta = self._substitute(subs2, delta)\n",
    "            theta = self._substitute(subs2, theta) \n",
    "            return [delta, theta, self._compose_substitutions(subs, subs2)]\n",
    "        return [delta, theta, subs]\n",
    "\n",
    "    def _change_letters_order_back(self, delta, theta, subs):\n",
    "        \"\"\" Give back the original delta and theta that were transformed with \n",
    "        the substitution subs\"\"\"\n",
    "        backsubs = {v:k for k,v in subs.items()}\n",
    "        delta = self._substitute(backsubs, delta)\n",
    "        theta = self._substitute(backsubs, theta)\n",
    "        return [delta, theta]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _initial_normalization(biseq):\n",
    "        m = re.match(\"(0(R|0))+\", biseq)\n",
    "        if m:\n",
    "            biseq = \"00\"*int((m.end()-m.start())/2) + biseq[m.end():]\n",
    "        return biseq\n",
    "    \n",
    "    @staticmethod\n",
    "    def _apply_rule(biseq, rule):\n",
    "        \"\"\" Function that applies the correction 'rule' in the biseq.\"\"\"\n",
    "        return biseq[:rule[0]] + rule[1] + biseq[rule[0] + 2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_eipal(seq, i):\n",
    "    \"\"\"Checks if a string seq is an E_i palindrome.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    l = len(seq)\n",
    "    if l == 1:\n",
    "        if seq == str(i):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for x in range(0, math.ceil(l/2)):\n",
    "        if seq[x] != ei[int(seq[l-1-x])]:\n",
    "            return False\n",
    "    return(True)\n",
    "def is_pal(seq):\n",
    "    \"\"\"Checks if a string is a palindrome.\"\"\"\n",
    "    l = len(seq)\n",
    "    if l == 1:\n",
    "        return(True)\n",
    "    for x in range(0, l // 2):\n",
    "        if seq[x] != seq[l - 1 - x]:\n",
    "            return(False)\n",
    "    return(True)\n",
    "def make_pal_closure(seq):\n",
    "    \"\"\"Makes palindromic closure from a string.\"\"\"\n",
    "    if is_pal(seq) == True:\n",
    "        return(seq)\n",
    "    i = 1\n",
    "    while is_pal(seq[i:]) != True:\n",
    "        i = i + 1\n",
    "    logging.debug(\"{0} longest palindromic suffix: {1}\"\n",
    "                  .format(seq, seq[i:]))\n",
    "    closure = seq + seq[i - 1::-1]\n",
    "    return(closure)\n",
    "def make_eipal_closure (seq, i):\n",
    "    \"\"\"Makes E_i-th palindromic closure of a string.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    if is_eipal(seq, i) == True:\n",
    "        return(seq)\n",
    "    j = 1\n",
    "    while is_eipal(seq[j:], i) != True:\n",
    "        j = j+1\n",
    "    logging.debug(\"{0} longest ei-palindromic suffix : {1}\"\n",
    "                  .format(seq,seq[j:]))\n",
    "    closure = seq\n",
    "    pref = seq[j-1::-1]\n",
    "    for letter in pref:\n",
    "        closure = closure + ei[int(letter)]\n",
    "    return(closure)\n",
    "def make012Word(delta, theta, steps, seed = \"\"):\n",
    "    \"\"\"Makes a GPS word over {0,1,2} from sequences delta and theta.\"\"\"\n",
    "    w = seed\n",
    "    for step in range(0,steps):\n",
    "        w = w + delta[step]\n",
    "        if theta[step] == \"R\":\n",
    "            w = gpc.makePalClosure(w)\n",
    "        elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "            w = makeEipalClosure(w, theta[step])\n",
    "        else:\n",
    "            logging.error(\"wrong symbol\")\n",
    "            return\n",
    "        logging.info(\"w{0} = {1}\".format(step+1,w))\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveNormalizer012:\n",
    "    def normalize(self, delta, theta):\n",
    "        \"\"\"Checks if delta and theta are normalized and if not, \n",
    "        returns the beginning of the normalized sequence.\"\"\"\n",
    "        if len(delta) != len(theta):\n",
    "            logging.error(\"The length of delta and theta must be equal.\")\n",
    "            return\n",
    "                         \n",
    "        w = \"\"\n",
    "        l=1\n",
    "        prefixes = []\n",
    "        for step in range(0,len(delta)):\n",
    "            w = w + delta[step]\n",
    "            if theta[step] == \"R\":\n",
    "                w = make_pal_closure(w)\n",
    "            elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "                w = make_eipal_closure(w, theta[step])\n",
    "            else:\n",
    "                logging.error(\"wrong symbol\")\n",
    "                return\n",
    "            prefixes.append(w)\n",
    "        logging.info(\"Prefixes from (delta, theta): \" + str(prefixes))\n",
    "        logging.info(\"Obtained word: \" + w)\n",
    "        \n",
    "        newdelta = delta[0]\n",
    "        newtheta = \"\"\n",
    "        while l <= len(w):\n",
    "            prefix = w[:l]\n",
    "            res = self._test_palindromicity(prefix)\n",
    "            if res[0] == True:\n",
    "                logging.info(prefix)\n",
    "                if l < len(w):\n",
    "                    newdelta = newdelta + w[l]\n",
    "                newtheta = newtheta + res[1]           \n",
    "            l=l+1\n",
    "        if newdelta == delta and newtheta == theta:\n",
    "            return (newdelta, newtheta, True)\n",
    "        else:\n",
    "            return (newdelta, newtheta, False)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _test_palindromicity(seq):\n",
    "        \"\"\"Checks if a seq is an palindrome or and E-palindrome and \n",
    "        returns its nature.\"\"\"\n",
    "        if is_eipal(seq,0):\n",
    "            return [True, \"0\"]\n",
    "        elif is_eipal(seq, 1):\n",
    "            return [True, \"1\"]\n",
    "        elif is_eipal(seq, 2):\n",
    "            return [True, \"2\"]\n",
    "        elif is_pal(seq):\n",
    "            return [True, \"R\"]\n",
    "        else:\n",
    "            return [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logging_level):\n",
    "    logging.getLogger().setLevel(logging_level)\n",
    "\n",
    "def Ei(i):\n",
    "    i = int(i)\n",
    "    ei = [0,0,0]\n",
    "    ei[i] = str(i)\n",
    "    ei[(i+1)%3] = str((2+i)%3)\n",
    "    ei[(i+2)%3] = str((1+i)%3)\n",
    "    return tuple(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for an applicable rule in('0011', '00RR')\n",
      "all non-prefix matches: []\n",
      "bi-sequence before changing the letters back: (0011, 00RR)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0011', '00RR', True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = \"0011\"\n",
    "theta = \"00RR\"\n",
    "set_logging(\"INFO\")\n",
    "normalizer = Normalizer012()\n",
    "normalizer.normalize(delta, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_normalizer = NaiveNormalizer012()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefixes from (delta, theta): ['0', '00', '00100', '00100100']\n",
      "Obtained word: 00100100\n",
      "0\n",
      "00\n",
      "00100\n",
      "00100100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0011', '00RR', True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_normalizer.normalize(delta, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nrc = Normalization012_rules_checker()\n",
    "#nrc.print_all_factor_rules_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
