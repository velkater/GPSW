{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import logging\n",
    "import math\n",
    "logging.basicConfig(format='%(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization012_rules_checker:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Prepare rules ...\n",
    "        \"\"\"\n",
    "        self._ei = {\"0\": Ei(\"0\"), \"1\": Ei(\"1\"), \"2\": Ei(\"2\")}\n",
    "        self._generate_factor_rules()        \n",
    "        self._compile_rules()\n",
    "    \n",
    "    _bad_prefixes_and_correction = (\n",
    "            (\"(00)*02\", \"0012\", 1), # 1.\n",
    "            (\"0010\", \"122100\", 2), # new added rule 29.\n",
    "            (\"00(120R)+10\", \"1220\", 3), # 2.\n",
    "            (\"0012(0R12)*01\", \"0R21\", 4),  # 3.\n",
    "            (\"001221(1R11)*12\", \"1R22\", 5), # 7.fixed rule and rewrite\n",
    "            (\"0012211R(111R)*10\", \"1100\", 6), # 8.\n",
    "            (\"001222\", \"210012\", 7), # 10.\n",
    "            (\"0012(0R12)*00\", \"0R20\", 8), # 12. fixed error\n",
    "            (\"00(120R)*11\", \"1221\", 9), # 13.-- 9\n",
    "            (\"(001221)*00122R\", \"211R\", 10), # 14. --10\n",
    "            (\"(001221)*001R\",\"120R\", 11), # 15. * because of rule 9 --11\n",
    "            (\"(001221)+0R\",\"002R\", 12), # 16. --12\n",
    "            (\"(001221)+1R2R\", \"222R\", 13), # 17. --13\n",
    "            (\"(001221)+002R2R\", \"210R\", 14), # 19. --14\n",
    "            (\"(001221)*00120R2R\", \"201R\", 15), # 18. --15\n",
    "            (\"00(120R)*122111\", \"1R11\", 16), # 20. -- 16\n",
    "            (\"0012(0R12)*0R2022\", \"2112\", 17), # 21. --17\n",
    "            (\"(00)+1212\", \"1R02\", 18), # 22. --18\n",
    "            (\"0012(0R12)+2020\", \"2R10\", 19), # 23. (can be also + and then rule3)\n",
    "            (\"(00)+1210\", \"1120\", 20), # 24. --20\n",
    "            (\"0012(0R12)*0R2112\", \"1022\", 21), # 25. -- 21\n",
    "            (\"001221(1R11)*0020\", \"2R10\", 22), # rewritten rule 26. -- 22\n",
    "            (\"001221(1R11)*1R2201\", \"0021\", 23), # 27. -- 23\n",
    "            (\"(00)+1202\", \"0R12\", 24), # new added rule 28. !!!! -- 24\n",
    "            (\"(00)+001111\", \"1R11\", 25), # from (011, R11)\n",
    "            (\"(00)+001020\", \"2R10\", 26), # from (012, R00)\n",
    "            (\"00(120R)+202111\", \"120021\", 27), # 1st added rule for 2 pseudopal\n",
    "            (\"(00)+121121\", \"200211\", 28), # 2nd added rule for 2 pseudopal\n",
    "            (\"00(120R)+211020\", \"220110\", 29), # 3rd added rule for 2 pseudopal\n",
    "            (\"001221(1R11)*1R220020\", \"211200\", 30) # 4th rules added for 2 pseudopal\n",
    "    )\n",
    "            \n",
    "    def find_applicable_rule(self, biseq):\n",
    "        \"\"\" Function looking is there is a bad prefix of a bad factor\n",
    "        inside the preprocessed biseq. If so, it returns the bad prefix position and the\n",
    "        correction to apply. If not, it returned an emply field (for now)??.\"\"\"\n",
    "    \n",
    "        logging.info(\"Checking for an applicable rule in\" + str((biseq[0::2], biseq[1::2])))\n",
    "        \n",
    "        applicable_rule = self._find_next_prefix_rule(biseq)\n",
    "        if applicable_rule:\n",
    "            return applicable_rule\n",
    "        \n",
    "        # If there is no bad prefix, we look for a factor rule\n",
    "        applicable_rule = self._find_next_factor_rule(biseq)\n",
    "        if applicable_rule:\n",
    "            return applicable_rule  \n",
    "    \n",
    "    def _find_next_prefix_rule(self, biseq):\n",
    "        # Looking for a prefix rule\n",
    "        for prefix_rule in self._prefix_rules:\n",
    "            match = re.match(prefix_rule[0], biseq)\n",
    "            if match:\n",
    "                logging.debug(\"prefix rule: \" + str(prefix_rule))\n",
    "                index = match.end() - 2\n",
    "                return [index, prefix_rule[1]] # bad prefix to repare\n",
    "    \n",
    "    def _find_next_factor_rule(self, biseq):\n",
    "        matches = []\n",
    "        for rules_index,_rules in self._factor_rules.items():\n",
    "            for rule in _rules:\n",
    "                match = re.match(rule, biseq)\n",
    "                if match:\n",
    "                    logging.debug(\"rule\" + str(rules_index) + \": \" + \\\n",
    "                    str(self._print_factor_rule(rule)) +\n",
    "                    \" in biseq \" + str((biseq[0::2], biseq[1::2])))\n",
    "                    \n",
    "                    position = match.end() - 2 # The position to be corrected\n",
    "                    #Index of match and correction:\n",
    "                    matches.append([position, self._factor_rules_replacement(rules_index, match.group(2))])\n",
    "                    biseq = biseq[:position + 3]\n",
    "\n",
    "        logging.info(\"all non-prefix matches: \" + str(matches))\n",
    "        # Final leftmost factor rule\n",
    "        if matches:\n",
    "            final = matches[0]\n",
    "            for rule in matches[1:]:\n",
    "                if rule[0] < final[0]:\n",
    "                    final = rule\n",
    "            logging.debug(\"Final change:\" + str(final))\n",
    "            return final \n",
    "    \n",
    "    def _factor_rules_replacement(self, index, rule):\n",
    "        ei = self._ei\n",
    "        if index == 1:\n",
    "            return rule[4]+\"R\"+ rule[2] + rule[3]\n",
    "        elif index == 2:\n",
    "            return rule[4]+rule[1]+rule[2] + \"R\"\n",
    "        elif index == 3:\n",
    "            return (rule[4]+ei[rule[1]][int(rule[3])] \n",
    "                    + ei[rule[1]][int(ei[rule[3]][int(rule[2])])] + rule[1])\n",
    "        elif index == 4:\n",
    "            return rule[6]+rule[1]+rule[2]+rule[3]+rule[4] + rule[5]\n",
    "        else:\n",
    "            logging.error(\"No replacement rule found\")\n",
    "    \n",
    "    def _generate_factor_rules(self):\n",
    "        ei = self._ei\n",
    "        a_b = [i[0]+i[1] for i in itertools.product('012', repeat = 2)]\n",
    "        i = [\"0\", \"1\", \"2\"]\n",
    "        \n",
    "        # we consider here b as b_2\n",
    "        self._rules1 = (k[0][0]+ \"R\" + ei[k[1]][int(k[0][1])]+ k[1] + \n",
    "                  k[0][1] + k[1] for k in itertools.product(a_b, i))\n",
    "        self._rules2 = (k[0][0]+ k[1] + ei[k[1]][int(k[0][1])]+ \"R\" + \n",
    "                  k[0][1] +\"R\" for k in itertools.product(a_b, i))\n",
    "\n",
    "        ij = itertools.permutations(\"012\", 2)\n",
    "        # we consider here b as b_1\n",
    "        self._rules3 = (k[0][0] + k[1][0] + k[0][1] + \n",
    "                   k[1][1] + ei[k[1][1]][int(ei[k[1][0]][int(k[0][1])])] + k[1][0] \n",
    "                  for k in itertools.product(a_b, ij))\n",
    "\n",
    "        ijk = itertools.permutations(\"012\", 3)\n",
    "        self._rules4 =(k[0][0] + k[1][0] + k[0][1] + k[1][1] + \n",
    "                 ei[k[1][1]][int(ei[k[1][0]][int(k[0][1])])] + k[1][2] + \n",
    "                    ei[k[1][2]][int(ei[k[1][0]][int(k[0][1])])] + k[1][2]\n",
    "                 for k in itertools.product(a_b, ijk))\n",
    "    def _compile_rules(self):\n",
    "        self._prefix_rules = tuple((re.compile(rule[0]),rule[1],rule[2])\n",
    "                                   for rule in self._bad_prefixes_and_correction)\n",
    "\n",
    "        self._factor_rules = {}\n",
    "        self._factor_rules[1] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules1 )\n",
    "        self._factor_rules[2] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules2 )\n",
    "        self._factor_rules[3] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules3 )\n",
    "        self._factor_rules[4] = tuple( re.compile('^([012R]{2})*('+ rule + ')')\n",
    "                                      for rule in self._rules4 )\n",
    "    \n",
    "    def print_all_factor_rules_readable(self):\n",
    "        for index in self._factor_rules:\n",
    "            self._print_factor_rules(index)\n",
    "            \n",
    "    def _print_factor_rules(self, index):\n",
    "        readable_rules = []\n",
    "        print(\"Factor rules \" + str(index))\n",
    "        for rule in self._factor_rules[index]:\n",
    "            readable_rules.append(self._print_factor_rule(rule))\n",
    "        print(tuple(readable_rules))\n",
    "                                  \n",
    "    def _print_factor_rule(self, rule):\n",
    "        rule_from_regex = rule.pattern.split(\"*\")[1][1:-1]\n",
    "        return (rule_from_regex[0::2], rule_from_regex[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer012:\n",
    "    def __init__(self):\n",
    "        self._rules_checker = Normalization012_rules_checker()\n",
    "        \n",
    "    def normalize(self, delta1, theta1):\n",
    "        \"\"\"Returns the normalized directive bi-sequence giving the same GPS word\n",
    "        as (delta1, theta1)\"\"\"\n",
    "        # Changing the letters to be in order 0,1,2\n",
    "        delta, theta, substitution = self._change_letters_order(delta1, theta1)\n",
    "        \n",
    "        # Interleaving delta and theta to get only one sequence from two\n",
    "        biseq = \"\".join(d + t for d, t in zip(delta, theta))\n",
    "\n",
    "        # Normalization of the prefix\n",
    "        biseq = self._initial_normalization(biseq)\n",
    "\n",
    "        # The main algorithm:\n",
    "        applicable_rule = self._rules_checker.find_applicable_rule(biseq)\n",
    "        while applicable_rule:\n",
    "            biseq = self._apply_rule(biseq, applicable_rule);\n",
    "            applicable_rule = self._rules_checker.find_applicable_rule(biseq)\n",
    "\n",
    "        # Post-processing\n",
    "        delta, theta = (biseq[0::2], biseq[1::2])\n",
    "        logging.info(\"bi-sequence before changing the letters back: (\" +\\\n",
    "                         delta + \", \" + theta + \")\")\n",
    "\n",
    "        delta, theta = self._change_letters_order_back(delta, theta, substitution)\n",
    "        \n",
    "        notchanged = (delta1 == delta) and (theta1 == theta)\n",
    "        return (delta, theta, notchanged)\n",
    "    \n",
    "    # Preprocessing\n",
    "    @staticmethod\n",
    "    def _substitute(dic, seq):\n",
    "        \"\"\"Substitutes letters in a word according to rules in dic, if there is\n",
    "        no rule for the letter, keeps the letter.\"\"\"\n",
    "        newseq = \"\"\n",
    "        for l in seq:\n",
    "            if l in dic:\n",
    "                newseq = newseq + dic[l]\n",
    "            else:\n",
    "                newseq = newseq + l\n",
    "        return newseq\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compose_substitutions(subs1, subs2):\n",
    "        \"\"\"Composes two substitutions of letter.\"\"\"\n",
    "        csub = {}\n",
    "        for l in [\"0\", \"1\", \"2\"]:\n",
    "            if l in subs1:\n",
    "                csub[l] = subs1[l]\n",
    "                if csub[l] in subs2:\n",
    "                    csub[l] = subs2[csub[l]]\n",
    "            elif l in subs2:\n",
    "                csub[l] = subs2[l]\n",
    "        return csub\n",
    "\n",
    "    def _change_letters_order(self, delta, theta):\n",
    "        \"\"\" Change (delta, theta) so that the word obtained is the same as the \n",
    "        original one, but the first symbol is 0, the second 1 and the third 2.\"\"\"\n",
    "        subs = {}\n",
    "        subs2 = {\"2\": \"1\", \"1\": \"2\"}\n",
    "        if delta[0] != \"0\":\n",
    "            subs = {delta[0]: \"0\", \"0\": delta[0]}\n",
    "            delta = self._substitute(subs, delta)\n",
    "            theta = self._substitute(subs, theta)\n",
    "        i = 0\n",
    "        l = len(delta)\n",
    "        while i < l and delta[i] == \"0\":\n",
    "            if theta[i] == \"2\":\n",
    "                return [delta, theta, subs]\n",
    "            if theta[i] == \"1\":\n",
    "                delta = self._substitute(subs2, delta)\n",
    "                theta = self._substitute(subs2, theta)            \n",
    "                return [delta, theta, compose_substitutions(subs, subs2)]\n",
    "            #otherwise whe have to continue\n",
    "            i = i + 1\n",
    "        if i < l and delta[i] == \"2\":\n",
    "            delta = self._substitute(subs2, delta)\n",
    "            theta = self._substitute(subs2, theta) \n",
    "            return [delta, theta, compose_substitutions(subs, subs2)]\n",
    "        return [delta, theta, subs]\n",
    "\n",
    "    def _change_letters_order_back(self, delta, theta, subs):\n",
    "        \"\"\" Give back the original delta and theta that were transformed with \n",
    "        the substitution subs\"\"\"\n",
    "        backsubs = {v:k for k,v in subs.items()}\n",
    "        delta = self._substitute(backsubs, delta)\n",
    "        theta = self._substitute(backsubs, theta)\n",
    "        return [delta, theta]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _initial_normalization(biseq):\n",
    "        m = re.match(\"(0(R|0))+\", biseq)\n",
    "        if m:\n",
    "            biseq = \"00\"*int((m.end()-m.start())/2) + biseq[m.end():]\n",
    "        return biseq\n",
    "    \n",
    "    @staticmethod\n",
    "    def _apply_rule(biseq, rule):\n",
    "        \"\"\" Function that applies the correction 'rule' in the biseq.\"\"\"\n",
    "        return biseq[:rule[0]] + rule[1] + biseq[rule[0] + 2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_eipal(seq, i):\n",
    "    \"\"\"Checks if a string seq is an E_i palindrome.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    l = len(seq)\n",
    "    if l == 1:\n",
    "        if seq == str(i):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for x in range(0, math.ceil(l/2)):\n",
    "        if seq[x] != ei[int(seq[l-1-x])]:\n",
    "            return False\n",
    "    return(True)\n",
    "def is_pal(seq):\n",
    "    \"\"\"Checks if a string is a palindrome.\"\"\"\n",
    "    l = len(seq)\n",
    "    if l == 1:\n",
    "        return(True)\n",
    "    for x in range(0, l // 2):\n",
    "        if seq[x] != seq[l - 1 - x]:\n",
    "            return(False)\n",
    "    return(True)\n",
    "def make_pal_closure(seq):\n",
    "    \"\"\"Makes palindromic closure from a string.\"\"\"\n",
    "    if is_pal(seq) == True:\n",
    "        return(seq)\n",
    "    i = 1\n",
    "    while is_pal(seq[i:]) != True:\n",
    "        i = i + 1\n",
    "    logging.debug(\"{0} longest palindromic suffix: {1}\"\n",
    "                  .format(seq, seq[i:]))\n",
    "    closure = seq + seq[i - 1::-1]\n",
    "    return(closure)\n",
    "def make_eipal_closure (seq, i):\n",
    "    \"\"\"Makes E_i-th palindromic closure of a string.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    if is_eipal(seq, i) == True:\n",
    "        return(seq)\n",
    "    j = 1\n",
    "    while is_eipal(seq[j:], i) != True:\n",
    "        j = j+1\n",
    "    logging.debug(\"{0} longest ei-palindromic suffix : {1}\"\n",
    "                  .format(seq,seq[j:]))\n",
    "    closure = seq\n",
    "    pref = seq[j-1::-1]\n",
    "    for letter in pref:\n",
    "        closure = closure + ei[int(letter)]\n",
    "    return(closure)\n",
    "def make012Word(delta, theta, steps, seed = \"\"):\n",
    "    \"\"\"Makes a GPS word over {0,1,2} from sequences delta and theta.\"\"\"\n",
    "    w = seed\n",
    "    for step in range(0,steps):\n",
    "        w = w + delta[step]\n",
    "        if theta[step] == \"R\":\n",
    "            w = gpc.makePalClosure(w)\n",
    "        elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "            w = makeEipalClosure(w, theta[step])\n",
    "        else:\n",
    "            logging.error(\"wrong symbol\")\n",
    "            return\n",
    "        logging.info(\"w{0} = {1}\".format(step+1,w))\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveNormalizer012:\n",
    "    def normalize(self, delta, theta):\n",
    "        \"\"\"Checks if delta and theta are normalized and if not, \n",
    "        returns the beginning of the normalized sequence.\"\"\"\n",
    "        if len(delta) != len(theta):\n",
    "            logging.error(\"The length of delta and theta must be equal.\")\n",
    "            return\n",
    "                         \n",
    "        w = \"\"\n",
    "        l=1\n",
    "        prefixes = []\n",
    "        for step in range(0,len(delta)):\n",
    "            w = w + delta[step]\n",
    "            if theta[step] == \"R\":\n",
    "                w = make_pal_closure(w)\n",
    "            elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "                w = make_eipal_closure(w, theta[step])\n",
    "            else:\n",
    "                logging.error(\"wrong symbol\")\n",
    "                return\n",
    "            prefixes.append(w)\n",
    "        logging.info(\"Prefixes from (delta, theta): \" + str(prefixes))\n",
    "        logging.info(\"Obtained word: \" + w)\n",
    "        \n",
    "        newdelta = delta[0]\n",
    "        newtheta = \"\"\n",
    "        while l <= len(w):\n",
    "            prefix = w[:l]\n",
    "            res = self._test_palindromicity(prefix)\n",
    "            if res[0] == True:\n",
    "                logging.info(prefix)\n",
    "                if l < len(w):\n",
    "                    newdelta = newdelta + w[l]\n",
    "                newtheta = newtheta + res[1]           \n",
    "            l=l+1\n",
    "        if newdelta == delta and newtheta == theta:\n",
    "            return (newdelta, newtheta, True)\n",
    "        else:\n",
    "            return (newdelta, newtheta, False)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _test_palindromicity(seq):\n",
    "        \"\"\"Checks if a seq is an palindrome or and E-palindrome and \n",
    "        returns its nature.\"\"\"\n",
    "        if is_eipal(seq,0):\n",
    "            return [True, \"0\"]\n",
    "        elif is_eipal(seq, 1):\n",
    "            return [True, \"1\"]\n",
    "        elif is_eipal(seq, 2):\n",
    "            return [True, \"2\"]\n",
    "        elif is_pal(seq):\n",
    "            return [True, \"R\"]\n",
    "        else:\n",
    "            return [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logging_level):\n",
    "    logging.getLogger().setLevel(logging_level)\n",
    "\n",
    "def Ei(i):\n",
    "    i = int(i)\n",
    "    ei = [0,0,0]\n",
    "    ei[i] = str(i)\n",
    "    ei[(i+1)%3] = str((2+i)%3)\n",
    "    ei[(i+2)%3] = str((1+i)%3)\n",
    "    return tuple(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for an applicable rule in('01200121', '0R201012')\n",
      "Checking for an applicable rule in('010200121', '02R201012')\n",
      "all non-prefix matches: [[14, '2201']]\n",
      "Checking for an applicable rule in('0102001201', '02R2010212')\n",
      "all non-prefix matches: [[18, '1022']]\n",
      "Checking for an applicable rule in('01020012012', '02R20102102')\n",
      "all non-prefix matches: []\n",
      "bi-sequence before changing the letters back: (01020012012, 02R20102102)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('21202210210', '20R02120120', False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = \"21022101\"\n",
    "theta = \"RR021210\"\n",
    "set_logging(\"INFO\")\n",
    "normalizer = Normalizer012()\n",
    "normalizer.normalize(delta, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_normalizer = NaiveNormalizer012()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefixes from (delta, theta): ['2', '212', '2120121', '212012120201202', '21201212020120220020120201012010', '212012120201202200201202010120101212012112212012120201202', '21201212020120220020120201012010121201211221201212020120201012010011012010121201212020120220020120201012010', '2120121202012022002012020101201012120121122120121202012020101201001101201012120121202012022002012020101201012120121122120121202012020101201001101201012120121']\n",
      "Obtained word: 2120121202012022002012020101201012120121122120121202012020101201001101201012120121202012022002012020101201012120121122120121202012020101201001101201012120121\n",
      "2\n",
      "21\n",
      "212\n",
      "2120121\n",
      "212012120201202\n",
      "21201212020120220020120201012010\n",
      "212012120201202200201202010120101212012112212012120201202\n",
      "2120121202012022002012020101201012120121122120121202012020101201001101201012120121\n",
      "21201212020120220020120201012010121201211221201212020120201012010011012010121201212020120220020120201012010\n",
      "212012120201202200201202010120101212012112212012120201202010120100110120101212012120201202200201202010120101212012112212012120201202\n",
      "2120121202012022002012020101201012120121122120121202012020101201001101201012120121202012022002012020101201012120121122120121202012020101201001101201012120121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('21202210210', '20R02120120', False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_normalizer.normalize(delta, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor rules 1\n",
      "(('000', 'R00'), ('020', 'R11'), ('010', 'R22'), ('021', 'R00'), ('011', 'R11'), ('001', 'R22'), ('012', 'R00'), ('002', 'R11'), ('022', 'R22'), ('100', 'R00'), ('120', 'R11'), ('110', 'R22'), ('121', 'R00'), ('111', 'R11'), ('101', 'R22'), ('112', 'R00'), ('102', 'R11'), ('122', 'R22'), ('200', 'R00'), ('220', 'R11'), ('210', 'R22'), ('221', 'R00'), ('211', 'R11'), ('201', 'R22'), ('212', 'R00'), ('202', 'R11'), ('222', 'R22'))\n",
      "Factor rules 2\n",
      "(('000', '0RR'), ('020', '1RR'), ('010', '2RR'), ('021', '0RR'), ('011', '1RR'), ('001', '2RR'), ('012', '0RR'), ('002', '1RR'), ('022', '2RR'), ('100', '0RR'), ('120', '1RR'), ('110', '2RR'), ('121', '0RR'), ('111', '1RR'), ('101', '2RR'), ('112', '0RR'), ('102', '1RR'), ('122', '2RR'), ('200', '0RR'), ('220', '1RR'), ('210', '2RR'), ('221', '0RR'), ('211', '1RR'), ('201', '2RR'), ('212', '0RR'), ('202', '1RR'), ('222', '2RR'))\n",
      "Factor rules 3\n",
      "(('002', '010'), ('001', '020'), ('001', '101'), ('002', '121'), ('002', '202'), ('001', '212'), ('010', '010'), ('012', '020'), ('012', '101'), ('010', '121'), ('010', '202'), ('012', '212'), ('021', '010'), ('020', '020'), ('020', '101'), ('021', '121'), ('021', '202'), ('020', '212'), ('102', '010'), ('101', '020'), ('101', '101'), ('102', '121'), ('102', '202'), ('101', '212'), ('110', '010'), ('112', '020'), ('112', '101'), ('110', '121'), ('110', '202'), ('112', '212'), ('121', '010'), ('120', '020'), ('120', '101'), ('121', '121'), ('121', '202'), ('120', '212'), ('202', '010'), ('201', '020'), ('201', '101'), ('202', '121'), ('202', '202'), ('201', '212'), ('210', '010'), ('212', '020'), ('212', '101'), ('210', '121'), ('210', '202'), ('212', '212'), ('221', '010'), ('220', '020'), ('220', '101'), ('221', '121'), ('221', '202'), ('220', '212'))\n",
      "Factor rules 4\n",
      "(('0021', '0122'), ('0012', '0211'), ('0012', '1022'), ('0021', '1200'), ('0021', '2011'), ('0012', '2100'), ('0102', '0122'), ('0120', '0211'), ('0120', '1022'), ('0102', '1200'), ('0102', '2011'), ('0120', '2100'), ('0210', '0122'), ('0201', '0211'), ('0201', '1022'), ('0210', '1200'), ('0210', '2011'), ('0201', '2100'), ('1021', '0122'), ('1012', '0211'), ('1012', '1022'), ('1021', '1200'), ('1021', '2011'), ('1012', '2100'), ('1102', '0122'), ('1120', '0211'), ('1120', '1022'), ('1102', '1200'), ('1102', '2011'), ('1120', '2100'), ('1210', '0122'), ('1201', '0211'), ('1201', '1022'), ('1210', '1200'), ('1210', '2011'), ('1201', '2100'), ('2021', '0122'), ('2012', '0211'), ('2012', '1022'), ('2021', '1200'), ('2021', '2011'), ('2012', '2100'), ('2102', '0122'), ('2120', '0211'), ('2120', '1022'), ('2102', '1200'), ('2102', '2011'), ('2120', '2100'), ('2210', '0122'), ('2201', '0211'), ('2201', '1022'), ('2210', '1200'), ('2210', '2011'), ('2201', '2100'))\n"
     ]
    }
   ],
   "source": [
    "nrc = Normalization012_rules_checker()\n",
    "nrc.print_all_factor_rules_readable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
