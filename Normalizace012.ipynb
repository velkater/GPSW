{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizace nad abecedou $\\{0,1,2\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gpc # library for work with GPS words over {0,1}\n",
    "import math\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with $E_i$-palindromes and closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Ei(i):\n",
    "    i = int(i)\n",
    "    ei = [0,0,0]\n",
    "    ei[i] = str(i)\n",
    "    ei[(i+1)%3] = str((2+i)%3)\n",
    "    ei[(i+2)%3] = str((1+i)%3)\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(Ei(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isEipal(seq, i):\n",
    "    \"\"\"Checks if a string seq is an E_i palindrome.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    l = len(seq)\n",
    "    if l == 1:\n",
    "        if seq == str(i):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for x in range(0, math.ceil(l/2)):\n",
    "        if seq[x] != ei[int(seq[l-1-x])]:\n",
    "            return False\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(isEipal(\"012\", 1))\n",
    "print(isEipal(\"002\", 1))\n",
    "print(isEipal(\"01201\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testPalindromicity(seq):\n",
    "    \"\"\"Checks if a seq is an palindrome or and E-palindrome and \n",
    "    returns its nature.\"\"\"\n",
    "    if isEipal(seq,0):\n",
    "        return [True, \"0\"]\n",
    "    elif isEipal(seq, 1):\n",
    "        return [True, \"1\"]\n",
    "    elif isEipal(seq, 2):\n",
    "        return [True, \"2\"]\n",
    "    elif gpc.isPal(seq):\n",
    "        return [True, \"R\"]\n",
    "    else:\n",
    "        return [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, '0']\n",
      "[True, '0']\n",
      "[True, 'R']\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(testPalindromicity(\"0210\"))\n",
    "print(testPalindromicity(\"00\")) # We want 00 to be an E_0-palindrome\n",
    "print(testPalindromicity(\"010\"))\n",
    "print(testPalindromicity(\"02110\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeEipalClosure (seq, i):\n",
    "    \"\"\"Makes E_i-th palindromic closure of a string.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    if isEipal(seq, i) == True:\n",
    "        return(seq)\n",
    "    j = 1\n",
    "    while isEipal(seq[j:], i) != True:\n",
    "        j = j+1\n",
    "    gpc.verboseprint(2, \"    {0} longest palindromic \\\n",
    "                     suffix : {1}\".format(seq,seq[j:]))\n",
    "    closure = seq\n",
    "    pref = seq[j-1::-1]\n",
    "    for letter in pref:\n",
    "        closure = closure + ei[int(letter)]\n",
    "    return(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "012\n",
      "0011\n",
      "00\n",
      "0212102021\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(makeEipalClosure(\"01\", 1))\n",
    "print(makeEipalClosure(\"00\", 2))\n",
    "print(makeEipalClosure(\"00\", 0))\n",
    "print(makeEipalClosure(\"021210\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make012Word(delta, theta, steps, seed = \"\"):\n",
    "    \"\"\"Makes a GPS over {0,1,2} from sequences delta and theta.\"\"\"\n",
    "    w = seed\n",
    "    for step in range(0,steps):\n",
    "        w = w + delta[step]\n",
    "        if theta[step] == \"R\":\n",
    "            w = zpu.makePalClosure(w)\n",
    "        elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "            w = makeEipalClosure(w, theta[step])\n",
    "        else:\n",
    "            print(\"wrong symbol\")\n",
    "            break\n",
    "        gpc.verboseprint(1, \"w{0} = {1}\".format(step+1,w))\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00112200'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "make012Word(\"0012\", \"0020\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive function for checking normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is012NormalizedNaive(delta, theta, steps):\n",
    "    \"\"\"Checks if delta and theta are normalized and if not, \n",
    "    returns the beginning of the normalized sequence.\"\"\"\n",
    "    w = \"\"\n",
    "    l=1\n",
    "    prefixes = []\n",
    "    for step in range(0,steps):\n",
    "        w = w + delta[step]\n",
    "        if theta[step] == \"R\":\n",
    "            w = gpc.makePalClosure(w)\n",
    "        elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "            w = makeEipalClosure(w, theta[step])\n",
    "        else:\n",
    "            print(\"wrong symbol\")\n",
    "            break\n",
    "        prefixes.append(w)\n",
    "    gpc.verboseprint(1, \"Prefixes from (delta, theta): \" + str(prefixes))\n",
    "    gpc.verboseprint(1, \"Obtained word: \" + w)\n",
    "    newdelta = delta[0]\n",
    "    newtheta = \"\"\n",
    "    while l <= len(w):\n",
    "        prefix = w[:l]\n",
    "        res = testPalindromicity(prefix)\n",
    "        if res[0] == True:\n",
    "            print(prefix)\n",
    "            if l < len(w):\n",
    "                newdelta = newdelta + w[l]\n",
    "            newtheta = newtheta + res[1]           \n",
    "        l=l+1\n",
    "    if newdelta == delta[:steps] and newtheta == theta[:steps]:\n",
    "        return [True, newdelta, newtheta]\n",
    "    else:\n",
    "        return [False, newdelta, newtheta]\n",
    "    \n",
    "    # The length of newdelta and newtheta are the same since the whole word \n",
    "    # is an palindrome because if was generated by the GPS construction\n",
    "    # from delta and theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "00\n",
      "0011\n",
      "001122\n",
      "00112200\n",
      "[False, '00120', '00210']\n",
      "0\n",
      "00\n",
      "0011\n",
      "001122\n",
      "[True, '0012', '0021']\n"
     ]
    }
   ],
   "source": [
    "# Example: \n",
    "print(is012NormalizedNaive(\"0012\", \"0020\", 4))\n",
    "print(is012NormalizedNaive(\"00120\", \"00210\", 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the normalization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the normalized bi-sequence for our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our implementation of the algorithm, we decided to work only with words\n",
    "that has 0 as first letter, 1 at second and 2 at third in order to make the \n",
    "algorithm easier to read and write. Of course, we want it working for all\n",
    "the bi-sequences, so we have to preprocess the bi-sequence so that the word\n",
    "obtained has first 0, then 1 and then 2. After the result of the algorithm,\n",
    "we will go back to the original letters order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substitute(dic, seq):\n",
    "    \"\"\"Substitutes letters in a word according to rules in dic, if there is\n",
    "    no rule for the letter, keeps the letter.\"\"\"\n",
    "    newseq = \"\"\n",
    "    for l in seq:\n",
    "        if l in dic:\n",
    "            newseq = newseq + dic[l]\n",
    "        else:\n",
    "            newseq = newseq + l\n",
    "    return newseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compose(subs1, subs2):\n",
    "    \"\"\"Composes two substitutions of letter.\"\"\"\n",
    "    csub = {}\n",
    "    for l in [\"0\", \"1\", \"2\"]:\n",
    "        if l in subs1:\n",
    "            csub[l] = subs1[l]\n",
    "            if csub[l] in subs2:\n",
    "                csub[l] = subs2[csub[l]]\n",
    "        elif l in subs2:\n",
    "            csub[l] = subs2[l]\n",
    "    return csub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': '0', '0': '1'}\n",
      "{'2': '0', '1': '1', '0': '2'}\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(compose({}, {\"1\": \"0\", \"0\": \"1\"}))\n",
    "print(compose({\"0\": \"1\", \"1\": \"0\"}, {\"1\" : \"2\", \"2\" : \"0\", \"0\": \"1\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeLettersOrder(delta, theta):\n",
    "    \"\"\" Change (delta, theta) so that the word obtained is the same at the \n",
    "    original one, but the first symbol is 0, the second 1 and the third 2.\"\"\"\n",
    "    subs = {}\n",
    "    subs2 = {\"2\": \"1\", \"1\": \"2\"}\n",
    "    if delta[0] != \"0\":\n",
    "        subs = {delta[0]: \"0\", \"0\": delta[0]}\n",
    "        delta = substitute(subs, delta)\n",
    "        theta = substitute(subs, theta)\n",
    "    i = 0\n",
    "    l = len(delta)\n",
    "    while i < l and delta[i] == \"0\":\n",
    "        if theta[i] == \"2\":\n",
    "            return [delta, theta, subs]\n",
    "        if theta[i] == \"1\":\n",
    "            delta = substitute(subs2, delta)\n",
    "            theta = substitute(subs2, theta)            \n",
    "            return [delta, theta, compose(subs, subs2)]\n",
    "        #otherwise whe have to continue\n",
    "        i = i + 1\n",
    "    if i < l and delta[i] == \"2\":\n",
    "        delta = substitute(subs2, delta)\n",
    "        theta = substitute(subs2, theta) \n",
    "        return [delta, theta, compose(subs, subs2)]\n",
    "    return [delta, theta, subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeLettersOrderBack(delta, theta, subs):\n",
    "    backsubs = {v:k for k,v in subs.items()}\n",
    "    delta = substitute(backsubs, delta)\n",
    "    theta = substitute(backsubs, theta)\n",
    "    return [delta, theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000011112222', '00000RR22001', {'2': '1', '1': '0', '0': '2'}]\n",
      "['111122220000', '11111RR00112'] \n",
      "\n",
      "['000', '002', {'2': '1', '1': '2'}]\n",
      "['000', '001'] \n",
      "\n",
      "['011', '02', {}]\n",
      "['011', '02'] \n",
      "\n",
      "['0001', '0RR0', {'2': '1', '1': '2'}]\n",
      "['0002', '0RR0'] \n",
      "\n",
      "['000012', '0RR02', {'2': '1', '1': '0', '0': '2'}]\n",
      "['111120', '1RR10']\n"
     ]
    }
   ],
   "source": [
    "# Example: \n",
    "ex1 = changeLettersOrder(\"111122220000\", \"11111RR00112\")\n",
    "print(ex1)\n",
    "print(changeLettersOrderBack(ex1[0], ex1[1], ex1[2]), \"\\n\")\n",
    "ex2 = changeLettersOrder(\"000\", \"001\")\n",
    "print(ex2)\n",
    "print(changeLettersOrderBack(ex2[0], ex2[1], ex2[2]), \"\\n\")\n",
    "ex3 = changeLettersOrder(\"011\", \"02\")\n",
    "print(ex3)\n",
    "print(changeLettersOrderBack(ex3[0], ex3[1], ex3[2]), \"\\n\")\n",
    "ex4 = changeLettersOrder(\"0002\", \"0RR0\")\n",
    "print(ex4)\n",
    "print(changeLettersOrderBack(ex4[0], ex4[1], ex4[2]), \"\\n\")\n",
    "ex5 = changeLettersOrder(\"111120\", \"1RR10\")\n",
    "print(ex5)\n",
    "print(changeLettersOrderBack(ex5[0], ex5[1], ex5[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the beginning of the bi-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want that every word beginning with $i^l$ (where $l$ is the largest\n",
    "possible) has a bi-directive sequence $(\\Delta, \\Theta)$ where the prefix\n",
    "of $\\Theta$ of lenght $l$ is equal to $E^l_i$. (We only solve the cases\n",
    "when there is an $R$ instead of $E_0$ (e.g. $(0000, RE_0RE_0) \\to (0000, E_0E_0E_0E_0)$, since the other cases are then solved\n",
    "within the normalization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialNormalization(delta, theta):\n",
    "    biseq = gpc.makeBiseq(delta, theta)\n",
    "    m = re.match(\"(0(R|0))+\", biseq)\n",
    "    if m:\n",
    "        biseq = \"00\"*int((m.end()-m.start())/2) + biseq[m.end():]\n",
    "    return gpc.parseBiseq(biseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000011', '000021']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialNormalization(\"000011\", \"R0R021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"prefixesrules.jpg\",width=600>\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List: bad prefix regex --> the new symbols instead of the last one\n",
    "bad_prefixes = [\n",
    "    [\"(00)*02\", \"0012\"], # 1.\n",
    "    [\"0012(0R12)*0R10\", \"1220\"], # 2.\n",
    "    [\"0012(0R12)+01\", \"0R21\"],  # 3.\n",
    "    [\"00121121\", \"2001\"], # 4.\n",
    "    [\"001210\", \"1120\"], # 5.\n",
    "    [\"001212\", \"1R02\"], # 6.\n",
    "    [\"0012211R(111R)*1112\", \"1R02\"], # 7.\n",
    "    [\"0012211R(111R)+10\", \"1100\"], # 8.\n",
    "    [\"001222\", \"210012\"], # 10.\n",
    "    [\"0011\", \"1221\"], # 11.\n",
    "    [\"0012(0R12)*00\", \"1R20\"], # 12. opraveno\n",
    "    [\"0012(0R12)*0R11\", \"1221\"], # 13.\n",
    "    [\"(001221)+00122R\", \"211R\"], # 14.\n",
    "    [\"(001221)+001R\",\"120R\"], # 15.\n",
    "    [\"(001221)+0R\",\"002R\"], # 16.\n",
    "    [\"(001221)+1R2R\", \"222R\"], # 17.\n",
    "    [\"(001221)+00120R2R\", \"201R\"], # 18.\n",
    "    [\"(001221)+002R2R\", \"210R\"], # 19.\n",
    "    [\"00(120R)+122111\", \"1R11\"], # 20.\n",
    "    [\"0012(0R12)+0R2022\", \"2112\"], # 21.\n",
    "    [\"(00)+1212\", \"1R02\"], # 22.\n",
    "    [\"0012(0R12)+2020\", \"2R10\"], # 23.\n",
    "    [\"(00)+1210\", \"1120\"], # 24.\n",
    "    [\"0012(0R12)+0R2112\", \"1022\"], # 25.\n",
    "    [\"0012211R(111R)+110021\", \"2R10\"], # 26.\n",
    "    [\"001221(1R11)+1R2201\", \"0021\"] # 27.\n",
    "]\n",
    "# Special case of prefix 9: \n",
    "# bad prefix regex --> the new symbols instead of the last two\n",
    "badprefix9 = [\"011R\", \"00120R\"] # 9. !! the last two letters are rewritten !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['000', 'R00'], ['020', 'R11'], ['010', 'R22'], ['021', 'R00'], ['011', 'R11'], ['001', 'R22'], ['012', 'R00'], ['002', 'R11'], ['022', 'R22'], ['100', 'R00'], ['120', 'R11'], ['110', 'R22'], ['121', 'R00'], ['111', 'R11'], ['101', 'R22'], ['112', 'R00'], ['102', 'R11'], ['122', 'R22'], ['200', 'R00'], ['220', 'R11'], ['210', 'R22'], ['221', 'R00'], ['211', 'R11'], ['201', 'R22'], ['212', 'R00'], ['202', 'R11'], ['222', 'R22']]\n"
     ]
    }
   ],
   "source": [
    "a_b2 = [i[0]+i[1] for i in itertools.product('012', repeat = 2)]\n",
    "i = [\"0\", \"1\", \"2\"]\n",
    "rules1 = [ [k[0][0]+Ei(k[1])[int(k[0][1])]+k[0][1], \"R\"+k[1]+k[1]] for k in itertools.product(a_b2, i)]\n",
    "rules2 = [ [k[0][0]+Ei(k[1])[int(k[0][1])]+k[0][1], k[1]+\"RR\"] for k in itertools.product(a_b2, i)]\n",
    "rules1 = [ [k[0][0]+Ei(k[1])[int(k[0][1])]+k[0][1], \"R\"+k[1]+k[1]] for k in itertools.product(a_b2, i)]\n",
    "print(rules1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-148-f62f02018dc5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-148-f62f02018dc5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    #['0'+ ''.join(i) for i in itertools.product('01', repeat=rep1)]\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def findNextBadFactor(biseq):\n",
    "    #['0'+ ''.join(i) for i in itertools.product('01', repeat=rep1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '0', '1', '2', '0', '1', '2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', '0'),\n",
       " ('0', '1'),\n",
       " ('0', '2'),\n",
       " ('1', '0'),\n",
       " ('1', '1'),\n",
       " ('1', '2'),\n",
       " ('2', '0'),\n",
       " ('2', '1'),\n",
       " ('2', '2')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([i[1]+Ei() for i in itertools. product('012', repeat = 2)])\n",
    "[i for i in itertools. product('012', repeat = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isNormalized(biseq):\n",
    "    matches = []\n",
    "    # Looking for bad prefixes\n",
    "    for prefixRule in bad_prefixes:\n",
    "        match = re.match(prefixRule[0], biseq)\n",
    "        if match:\n",
    "            index = match.end() - 2\n",
    "            matches.append([index, prefixRule[1], 2])\n",
    "            # the third number is the length of the sequence we replace\n",
    "            \n",
    "    # Special case of prefix 9\n",
    "    match = re.match(badprefix9[0], biseq)\n",
    "    if match:\n",
    "        index = match.end() - 4\n",
    "        matches.append([index, prefixRule[1], 4])\n",
    "    # Final \"leading\" prefix    \n",
    "    final = []\n",
    "    if matches:\n",
    "        final = matches[0]\n",
    "        for rule in matches[1:]:\n",
    "            if rule[0] < final[0]:\n",
    "                final = rule\n",
    "                return final\n",
    "                \n",
    "    # Looking for bad factors if there is no bad prefix\n",
    "    findNextBadFactor()\n",
    "    \n",
    "    \n",
    "    # Rule to apply: choosing smallest index in the word\n",
    "    #print(matches)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyRule(biseq, rule):\n",
    "    return biseq[:rule[0]] + rule[1] + biseq[rule[0] + rule[2]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(delta, theta):\n",
    "    \"\"\"Returns the normalized directive bi-sequence giving the same GPS word\n",
    "    as (delta, theta)\"\"\"\n",
    "    # Normalization of the letters order\n",
    "    [delta, theta, substitution] = changeLettersOrder(delta, theta)\n",
    "    \n",
    "    # Normalization of the prefix\n",
    "    [delta, theta] = initialNormalization(delta, theta)\n",
    "    \n",
    "    # The main algorithm\n",
    "    biseq = gpc.makeBiseq(delta, theta)\n",
    "    applicableRule = []\n",
    "    applicableRule = isNormalized(biseq)    \n",
    "    while applicableRule:\n",
    "        biseq = applyRule(biseq, applicableRule);\n",
    "        applicableRule = isNormalized(biseq)\n",
    "    \n",
    "    [delta, theta] = gpc.parseBiseq(biseq)\n",
    "    print(delta, theta)\n",
    "    return [changeLettersOrderBack(delta, theta, substitution)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0112 02R0\n"
     ]
    }
   ],
   "source": [
    "r = normalize(\"010\", \"020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "01\n",
      "0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, '011', '021']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is012NormalizedNaive(\"011\", \"021\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpc.verbose =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "01\n",
      "010\n",
      "01020\n",
      "01020120212\n",
      "010201202121020212012101\n",
      "0102012021210202120121010212101201020\n",
      "01020120212102021201210102121012010202101020120212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False, '01021102', '02R01201']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is012NormalizedNaive(\"0102110\", \"02R0121\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-c05e46e02805>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-c05e46e02805>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    re.search(\"abb\", \"000abbabb\"[, 3, 6])\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "re.search(\"abb\", \"000abbabb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ww'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"wwweeee\"[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
