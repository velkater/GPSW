{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizace nad abecedou $\\{0,1,2\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gpc # library for work with GPS words over {0,1}\n",
    "import math\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with $E_i$-palindromes and closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Ei(i):\n",
    "    i = int(i)\n",
    "    ei = [0,0,0]\n",
    "    ei[i] = str(i)\n",
    "    ei[(i+1)%3] = str((2+i)%3)\n",
    "    ei[(i+2)%3] = str((1+i)%3)\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(Ei(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isEipal(seq, i):\n",
    "    \"\"\"Checks if a string seq is an E_i palindrome.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    l = len(seq)\n",
    "    if l == 1:\n",
    "        if seq == str(i):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for x in range(0, math.ceil(l/2)):\n",
    "        if seq[x] != ei[int(seq[l-1-x])]:\n",
    "            return False\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(isEipal(\"012\", 1))\n",
    "print(isEipal(\"002\", 1))\n",
    "print(isEipal(\"01201\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testPalindromicity(seq):\n",
    "    \"\"\"Checks if a seq is an palindrome or and E-palindrome and \n",
    "    returns its nature.\"\"\"\n",
    "    if isEipal(seq,0):\n",
    "        return [True, \"0\"]\n",
    "    elif isEipal(seq, 1):\n",
    "        return [True, \"1\"]\n",
    "    elif isEipal(seq, 2):\n",
    "        return [True, \"2\"]\n",
    "    elif gpc.isPal(seq):\n",
    "        return [True, \"R\"]\n",
    "    else:\n",
    "        return [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, '0']\n",
      "[True, '0']\n",
      "[True, 'R']\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(testPalindromicity(\"0210\"))\n",
    "print(testPalindromicity(\"00\")) # We want 00 to be an E_0-palindrome\n",
    "print(testPalindromicity(\"010\"))\n",
    "print(testPalindromicity(\"02110\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeEipalClosure (seq, i):\n",
    "    \"\"\"Makes E_i-th palindromic closure of a string.\"\"\"\n",
    "    ei = Ei(i)\n",
    "    if isEipal(seq, i) == True:\n",
    "        return(seq)\n",
    "    j = 1\n",
    "    while isEipal(seq[j:], i) != True:\n",
    "        j = j+1\n",
    "    gpc.verboseprint(2, \"    {0} longest palindromic \\\n",
    "                     suffix : {1}\".format(seq,seq[j:]))\n",
    "    closure = seq\n",
    "    pref = seq[j-1::-1]\n",
    "    for letter in pref:\n",
    "        closure = closure + ei[int(letter)]\n",
    "    return(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "012\n",
      "0011\n",
      "00\n",
      "0212102021\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(makeEipalClosure(\"01\", 1))\n",
    "print(makeEipalClosure(\"00\", 2))\n",
    "print(makeEipalClosure(\"00\", 0))\n",
    "print(makeEipalClosure(\"021210\", 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make012Word(delta, theta, steps, seed = \"\"):\n",
    "    \"\"\"Makes a GPS over {0,1,2} from sequences delta and theta.\"\"\"\n",
    "    w = seed\n",
    "    for step in range(0,steps):\n",
    "        w = w + delta[step]\n",
    "        if theta[step] == \"R\":\n",
    "            w = zpu.makePalClosure(w)\n",
    "        elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "            w = makeEipalClosure(w, theta[step])\n",
    "        else:\n",
    "            print(\"wrong symbol\")\n",
    "            break\n",
    "        gpc.verboseprint(1, \"w{0} = {1}\".format(step+1,w))\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00112200'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "make012Word(\"0012\", \"0020\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive function for checking normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is012NormalizedNaive(delta, theta, steps):\n",
    "    \"\"\"Checks if delta and theta are normalized and if not, \n",
    "    returns the beginning of the normalized sequence.\"\"\"\n",
    "    w = \"\"\n",
    "    l=1\n",
    "    prefixes = []\n",
    "    for step in range(0,steps):\n",
    "        w = w + delta[step]\n",
    "        if theta[step] == \"R\":\n",
    "            w = gpc.makePalClosure(w)\n",
    "        elif theta[step] in [\"0\", \"1\", \"2\"]:\n",
    "            w = makeEipalClosure(w, theta[step])\n",
    "        else:\n",
    "            print(\"wrong symbol\")\n",
    "            break\n",
    "        prefixes.append(w)\n",
    "    gpc.verboseprint(1, \"Prefixes from (delta, theta): \" + str(prefixes))\n",
    "    gpc.verboseprint(1, \"Obtained word: \" + w)\n",
    "    newdelta = delta[0]\n",
    "    newtheta = \"\"\n",
    "    while l <= len(w):\n",
    "        prefix = w[:l]\n",
    "        res = testPalindromicity(prefix)\n",
    "        if res[0] == True:\n",
    "            print(prefix)\n",
    "            if l < len(w):\n",
    "                newdelta = newdelta + w[l]\n",
    "            newtheta = newtheta + res[1]           \n",
    "        l=l+1\n",
    "    if newdelta == delta[:steps] and newtheta == theta[:steps]:\n",
    "        return [True, newdelta, newtheta]\n",
    "    else:\n",
    "        return [False, newdelta, newtheta]\n",
    "    \n",
    "    # The length of newdelta and newtheta are the same since the whole word \n",
    "    # is an palindrome because if was generated by the GPS construction\n",
    "    # from delta and theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "00\n",
      "0011\n",
      "001122\n",
      "00112200\n",
      "[False, '00120', '00210']\n",
      "0\n",
      "00\n",
      "0011\n",
      "001122\n",
      "[True, '0012', '0021']\n"
     ]
    }
   ],
   "source": [
    "# Example: \n",
    "print(is012NormalizedNaive(\"0012\", \"0020\", 4))\n",
    "print(is012NormalizedNaive(\"00120\", \"00210\", 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the normalization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the normalized bi-sequence for our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our implementation of the algorithm, we decided to work only with words\n",
    "that has 0 as first letter, 1 at second and 2 at third in order to make the \n",
    "algorithm easier to read and write. Of course, we want it working for all\n",
    "the bi-sequences, so we have to preprocess the bi-sequence so that the word\n",
    "obtained has first 0, then 1 and then 2. After the result of the algorithm,\n",
    "we will go back to the original letters order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substitute(dic, seq):\n",
    "    \"\"\"Substitutes letters in a word according to rules in dic, if there is\n",
    "    no rule for the letter, keeps the letter.\"\"\"\n",
    "    newseq = \"\"\n",
    "    for l in seq:\n",
    "        if l in dic:\n",
    "            newseq = newseq + dic[l]\n",
    "        else:\n",
    "            newseq = newseq + l\n",
    "    return newseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compose(subs1, subs2):\n",
    "    \"\"\"Composes two substitutions of letter.\"\"\"\n",
    "    csub = {}\n",
    "    for l in [\"0\", \"1\", \"2\"]:\n",
    "        if l in subs1:\n",
    "            csub[l] = subs1[l]\n",
    "            if csub[l] in subs2:\n",
    "                csub[l] = subs2[csub[l]]\n",
    "        elif l in subs2:\n",
    "            csub[l] = subs2[l]\n",
    "    return csub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '1', '1': '0'}\n",
      "{'0': '2', '1': '1', '2': '0'}\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "print(compose({}, {\"1\": \"0\", \"0\": \"1\"}))\n",
    "print(compose({\"0\": \"1\", \"1\": \"0\"}, {\"1\" : \"2\", \"2\" : \"0\", \"0\": \"1\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeLettersOrder(delta, theta):\n",
    "    \"\"\" Change (delta, theta) so that the word obtained is the same at the \n",
    "    original one, but the first symbol is 0, the second 1 and the third 2.\"\"\"\n",
    "    subs = {}\n",
    "    subs2 = {\"2\": \"1\", \"1\": \"2\"}\n",
    "    if delta[0] != \"0\":\n",
    "        subs = {delta[0]: \"0\", \"0\": delta[0]}\n",
    "        delta = substitute(subs, delta)\n",
    "        theta = substitute(subs, theta)\n",
    "    i = 0\n",
    "    l = len(delta)\n",
    "    while i < l and delta[i] == \"0\":\n",
    "        if theta[i] == \"2\":\n",
    "            return [delta, theta, subs]\n",
    "        if theta[i] == \"1\":\n",
    "            delta = substitute(subs2, delta)\n",
    "            theta = substitute(subs2, theta)            \n",
    "            return [delta, theta, compose(subs, subs2)]\n",
    "        #otherwise whe have to continue\n",
    "        i = i + 1\n",
    "    if i < l and delta[i] == \"2\":\n",
    "        delta = substitute(subs2, delta)\n",
    "        theta = substitute(subs2, theta) \n",
    "        return [delta, theta, compose(subs, subs2)]\n",
    "    return [delta, theta, subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeLettersOrderBack(delta, theta, subs):\n",
    "    backsubs = {v:k for k,v in subs.items()}\n",
    "    delta = substitute(backsubs, delta)\n",
    "    theta = substitute(backsubs, theta)\n",
    "    return [delta, theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000011112222', '00000RR22001', {'0': '2', '1': '0', '2': '1'}]\n",
      "['111122220000', '11111RR00112'] \n",
      "\n",
      "['000', '002', {'2': '1', '1': '2'}]\n",
      "['000', '001'] \n",
      "\n",
      "['011', '02', {}]\n",
      "['011', '02'] \n",
      "\n",
      "['0001', '0RR0', {'2': '1', '1': '2'}]\n",
      "['0002', '0RR0'] \n",
      "\n",
      "['000012', '0RR02', {'0': '2', '1': '0', '2': '1'}]\n",
      "['111120', '1RR10']\n"
     ]
    }
   ],
   "source": [
    "# Example: \n",
    "ex1 = changeLettersOrder(\"111122220000\", \"11111RR00112\")\n",
    "print(ex1)\n",
    "print(changeLettersOrderBack(ex1[0], ex1[1], ex1[2]), \"\\n\")\n",
    "ex2 = changeLettersOrder(\"000\", \"001\")\n",
    "print(ex2)\n",
    "print(changeLettersOrderBack(ex2[0], ex2[1], ex2[2]), \"\\n\")\n",
    "ex3 = changeLettersOrder(\"011\", \"02\")\n",
    "print(ex3)\n",
    "print(changeLettersOrderBack(ex3[0], ex3[1], ex3[2]), \"\\n\")\n",
    "ex4 = changeLettersOrder(\"0002\", \"0RR0\")\n",
    "print(ex4)\n",
    "print(changeLettersOrderBack(ex4[0], ex4[1], ex4[2]), \"\\n\")\n",
    "ex5 = changeLettersOrder(\"111120\", \"1RR10\")\n",
    "print(ex5)\n",
    "print(changeLettersOrderBack(ex5[0], ex5[1], ex5[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the beginning of the bi-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want that every word beginning with $i^l$ (where $l$ is the largest\n",
    "possible) has a bi-directive sequence $(\\Delta, \\Theta)$ where the prefix\n",
    "of $\\Theta$ of lenght $l$ is equal to $E^l_i$. (We only solve the cases\n",
    "when there is an $R$ instead of $E_0$ (e.g. $(0000, RE_0RE_0) \\to (0000, E_0E_0E_0E_0)$, since the other cases are then solved\n",
    "within the normalization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialNormalization(delta, theta):\n",
    "    biseq = gpc.makeBiseq(delta, theta)\n",
    "    m = re.match(\"(0(R|0))+\", biseq)\n",
    "    if m:\n",
    "        biseq = \"00\"*int((m.end()-m.start())/2) + biseq[m.end():]\n",
    "    return gpc.parseBiseq(biseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000011', '000021']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialNormalization(\"000011\", \"R0R021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"prefixesrules.jpg\",width=600>\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List: bad prefix regex --> the new symbols instead of the last one\n",
    "bad_prefixes = [\n",
    "    [\"(00)*02\", \"0012\"], # 1.\n",
    "    [\"0012(0R12)*0R10\", \"1220\"], # 2.\n",
    "    [\"0012(0R12)+01\", \"0R21\"],  # 3.\n",
    "    [\"00121121\", \"2001\"], # 4.\n",
    "    [\"001210\", \"1120\"], # 5.\n",
    "    [\"001212\", \"1R02\"], # 6.\n",
    "    [\"0012211R(111R)*1112\", \"1R02\"], # 7.\n",
    "    [\"0012211R(111R)+10\", \"1100\"], # 8.\n",
    "    [\"001222\", \"210012\"], # 10.\n",
    "    [\"0011\", \"1221\"], # 11.\n",
    "    [\"0012(0R12)*00\", \"1R20\"], # 12. opraveno\n",
    "    [\"0012(0R12)*0R11\", \"1221\"], # 13.\n",
    "    [\"(001221)+00122R\", \"211R\"], # 14.\n",
    "    [\"(001221)+001R\",\"120R\"], # 15.\n",
    "    [\"(001221)+0R\",\"002R\"], # 16.\n",
    "    [\"(001221)+1R2R\", \"222R\"], # 17.\n",
    "    [\"(001221)+00120R2R\", \"201R\"], # 18.\n",
    "    [\"(001221)+002R2R\", \"210R\"], # 19.\n",
    "    [\"00(120R)+122111\", \"1R11\"], # 20.\n",
    "    [\"0012(0R12)+0R2022\", \"2112\"], # 21.\n",
    "    [\"(00)+1212\", \"1R02\"], # 22.\n",
    "    [\"0012(0R12)+2020\", \"2R10\"], # 23.\n",
    "    [\"(00)+1210\", \"1120\"], # 24.\n",
    "    [\"0012(0R12)+0R2112\", \"1022\"], # 25.\n",
    "    [\"0012211R(111R)+110021\", \"2R10\"], # 26.\n",
    "    [\"001221(1R11)+1R2201\", \"0021\"] # 27.\n",
    "]\n",
    "# Special case of prefix 9: \n",
    "# bad prefix regex --> the new symbols instead of the last two\n",
    "badprefix9 = [\"011R\", \"00120R\"] # 9. !! the last two letters are rewritten !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intern rules 1:\n",
      "['0R0000', '0R2101', '0R1202', '0R2010', '0R1111', '0R0212', '0R1020', '0R0121', '0R2222', '1R0000', '1R2101', '1R1202', '1R2010', '1R1111', '1R0212', '1R1020', '1R0121', '1R2222', '2R0000', '2R2101', '2R1202', '2R2010', '2R1111', '2R0212', '2R1020', '2R0121', '2R2222'] \n",
      "\n",
      "Intern rules 2:\n",
      "['000R0R', '012R0R', '021R0R', '002R1R', '011R1R', '020R1R', '001R2R', '010R2R', '022R2R', '100R0R', '112R0R', '121R0R', '102R1R', '111R1R', '120R1R', '101R2R', '110R2R', '122R2R', '200R0R', '212R0R', '221R0R', '202R1R', '211R1R', '220R1R', '201R2R', '210R2R', '222R2R'] \n",
      "\n",
      "Intern rules 3:\n",
      "['000120', '000210', '010011', '010221', '020022', '020112', '001100', '001220', '011021', '011201', '021002', '021122', '002110', '002200', '012001', '012211', '022012', '022102', '100120', '100210', '110011', '110221', '120022', '120112', '101100', '101220', '111021', '111201', '121002', '121122', '102110', '102200', '112001', '112211', '122012', '122102', '200120', '200210', '210011', '210221', '220022', '220112', '201100', '201220', '211021', '211201', '221002', '221122', '202110', '202200', '212001', '212211', '222012', '222102'] \n",
      "\n",
      "-----------\n",
      "More readable rules:\n",
      "Rule 1: (ab_1b_2, RE_iE_i) where b_1=E_i(b_2)\n",
      "[['000', 'R00'], ['020', 'R11'], ['010', 'R22'], ['021', 'R00'], ['011', 'R11'], ['001', 'R22'], ['012', 'R00'], ['002', 'R11'], ['022', 'R22'], ['100', 'R00'], ['120', 'R11'], ['110', 'R22'], ['121', 'R00'], ['111', 'R11'], ['101', 'R22'], ['112', 'R00'], ['102', 'R11'], ['122', 'R22'], ['200', 'R00'], ['220', 'R11'], ['210', 'R22'], ['221', 'R00'], ['211', 'R11'], ['201', 'R22'], ['212', 'R00'], ['202', 'R11'], ['222', 'R22']] \n",
      "\n",
      "Rule 1: (ab_1b_2, E_iRR) where b_1=E_i(b_2)\n",
      "[['000', '0RR'], ['020', '1RR'], ['010', '2RR'], ['021', '0RR'], ['011', '1RR'], ['001', '2RR'], ['012', '0RR'], ['002', '1RR'], ['022', '2RR'], ['100', '0RR'], ['120', '1RR'], ['110', '2RR'], ['121', '0RR'], ['111', '1RR'], ['101', '2RR'], ['112', '0RR'], ['102', '1RR'], ['122', '2RR'], ['200', '0RR'], ['220', '1RR'], ['210', '2RR'], ['221', '0RR'], ['211', '1RR'], ['201', '2RR'], ['212', '0RR'], ['202', '1RR'], ['222', '2RR']] \n",
      "\n",
      "Rule 1: (ab_1b_2, E_iE_jE_i) where E_i(b_1)=E_j(b_2)\n",
      "[['002', '010'], ['001', '020'], ['001', '101'], ['002', '121'], ['002', '202'], ['001', '212'], ['010', '010'], ['012', '020'], ['012', '101'], ['010', '121'], ['010', '202'], ['012', '212'], ['021', '010'], ['020', '020'], ['020', '101'], ['021', '121'], ['021', '202'], ['020', '212'], ['102', '010'], ['101', '020'], ['101', '101'], ['102', '121'], ['102', '202'], ['101', '212'], ['110', '010'], ['112', '020'], ['112', '101'], ['110', '121'], ['110', '202'], ['112', '212'], ['121', '010'], ['120', '020'], ['120', '101'], ['121', '121'], ['121', '202'], ['120', '212'], ['202', '010'], ['201', '020'], ['201', '101'], ['202', '121'], ['202', '202'], ['201', '212'], ['210', '010'], ['212', '020'], ['212', '101'], ['210', '121'], ['210', '202'], ['212', '212'], ['221', '010'], ['220', '020'], ['220', '101'], ['221', '121'], ['221', '202'], ['220', '212']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_b = [i[0]+i[1] for i in itertools.product('012', repeat = 2)]\n",
    "i = [\"0\", \"1\", \"2\"]\n",
    "rules1 = [ k[0][0]+ \"R\" + Ei(k[1])[int(k[0][1])]+ k[1] + k[0][1] +k[1] for k in itertools.product(a_b, i)]\n",
    "rules2 = [ k[0][0]+ k[1] + Ei(k[1])[int(k[0][1])]+ \"R\" + k[0][1] +\"R\" for k in itertools.product(a_b, i)]\n",
    "\n",
    "ij = list(itertools.permutations(\"012\", 2))\n",
    "rules3 = [ k[0][0] + k[1][0] + k[0][1] + \n",
    "           k[1][1] + Ei(k[1][1])[int(Ei(k[1][0])[int(k[0][1])])] + k[1][0] \n",
    "          for k in itertools.product(a_b, ij)]\n",
    "print(\"Intern rules 1:\")\n",
    "print(rules1, \"\\n\")\n",
    "print(\"Intern rules 2:\")\n",
    "print(rules2, \"\\n\")\n",
    "print(\"Intern rules 3:\")\n",
    "print(rules3, \"\\n\")\n",
    "\n",
    "# Rules in more \"readable\" form\n",
    "print(\"-----------\")\n",
    "print(\"More readable rules:\")\n",
    "rules1Readable = [gpc.parseBiseq(rule) for rule in rules1]\n",
    "print( \"Rule 1: (ab_1b_2, RE_iE_i) where b_1=E_i(b_2)\")\n",
    "print(rules1Readable, \"\\n\")\n",
    "\n",
    "rules2Readable = [gpc.parseBiseq(rule) for rule in rules2]\n",
    "print( \"Rule 1: (ab_1b_2, E_iRR) where b_1=E_i(b_2)\")\n",
    "print(rules2Readable, \"\\n\") \n",
    "\n",
    "rules3Readable = [gpc.parseBiseq(rule) for rule in rules3]\n",
    "print( \"Rule 1: (ab_1b_2, E_iE_jE_i) where E_i(b_1)=E_j(b_2)\")\n",
    "print(rules3Readable, \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findNextBadFactor(biseq):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isNormalized(biseq):\n",
    "    matches = []\n",
    "    # Looking for bad prefixes\n",
    "    for prefixRule in bad_prefixes:\n",
    "        match = re.match(prefixRule[0], biseq)\n",
    "        if match:\n",
    "            index = match.end() - 2\n",
    "            matches.append([index, prefixRule[1], 2])\n",
    "            # the third number is the length of the sequence we replace\n",
    "            \n",
    "    # Special case of prefix 9\n",
    "    match = re.match(badprefix9[0], biseq)\n",
    "    if match:\n",
    "        index = match.end() - 4\n",
    "        matches.append([index, prefixRule[1], 4])\n",
    "    # Final \"leading\" prefix    \n",
    "    final = []\n",
    "    if matches:\n",
    "        final = matches[0]\n",
    "        for rule in matches[1:]:\n",
    "            if rule[0] < final[0]:\n",
    "                final = rule\n",
    "                return final\n",
    "                \n",
    "    # Looking for bad factors if there is no bad prefix\n",
    "    findNextBadFactor()\n",
    "    \n",
    "    \n",
    "    # Rule to apply: choosing smallest index in the word\n",
    "    #print(matches)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyRule(biseq, rule):\n",
    "    return biseq[:rule[0]] + rule[1] + biseq[rule[0] + rule[2]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(delta, theta):\n",
    "    \"\"\"Returns the normalized directive bi-sequence giving the same GPS word\n",
    "    as (delta, theta)\"\"\"\n",
    "    # Normalization of the letters order\n",
    "    [delta, theta, substitution] = changeLettersOrder(delta, theta)\n",
    "    \n",
    "    # Normalization of the prefix\n",
    "    [delta, theta] = initialNormalization(delta, theta)\n",
    "    \n",
    "    # The main algorithm\n",
    "    biseq = gpc.makeBiseq(delta, theta)\n",
    "    applicableRule = []\n",
    "    applicableRule = isNormalized(biseq)    \n",
    "    while applicableRule:\n",
    "        biseq = applyRule(biseq, applicableRule);\n",
    "        applicableRule = isNormalized(biseq)\n",
    "    \n",
    "    [delta, theta] = gpc.parseBiseq(biseq)\n",
    "    print(delta, theta)\n",
    "    return [changeLettersOrderBack(delta, theta, substitution)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'findNextBadFactor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8c763e6cc5bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"010\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"020\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-5b757a872855>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(delta, theta)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbiseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeBiseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mapplicableRule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mapplicableRule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misNormalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mapplicableRule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbiseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplicableRule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-21b21cccaa15>\u001b[0m in \u001b[0;36misNormalized\u001b[0;34m(biseq)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Looking for bad factors if there is no bad prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mfindNextBadFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'findNextBadFactor' is not defined"
     ]
    }
   ],
   "source": [
    "r = normalize(\"010\", \"020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "01\n",
      "0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, '011', '021']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is012NormalizedNaive(\"011\", \"021\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpc.verbose =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefixes from (delta, theta): ['0', '01', '010', '01020', '01020120212', '010201202121020212012101', '01020120212102021201210102121012010202101020120212']\n",
      "Obtained word: 01020120212102021201210102121012010202101020120212\n",
      "0\n",
      "01\n",
      "010\n",
      "01020\n",
      "01020120212\n",
      "010201202121020212012101\n",
      "0102012021210202120121010212101201020\n",
      "01020120212102021201210102121012010202101020120212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False, '01021102', '02R01201']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is012NormalizedNaive(\"0102110\", \"02R0121\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(3, 6), match='abb'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"abb\", \"000abbabb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ww'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"wwweeee\"[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
